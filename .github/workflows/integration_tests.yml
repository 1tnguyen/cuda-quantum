name: Nightly integration tests

# Run on request and every day at 3 AM UTC
on:
  workflow_dispatch:
    inputs:
      target:
        description: 'Target (choose nightly to run like nightly tests)'
        required: true
        default: 'nightly'
        type: choice
        options:
          - nightly
          - ionq
          - iqm
          - oqc
          - quantinuum
          - nvcf
      single_test_name:
        type: string
        required: false
        description: 'Single test (e.g., targettests/quantinuum/load_value.cpp). Runs default tests if left blank'
      target_machine:
        type: string
        required: false
        description: 'Target machine (e.g., H1-1E).'
  schedule:
    - cron: 0 3 * * *

jobs:
  build_nvcf_image:
    name: Build NVCF deployment image
    runs-on: ubuntu-latest
    environment: backend-validation
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up context for buildx
        run: |
          docker context create builder_context

      - name: Set up buildx runner
        uses: docker/setup-buildx-action@v3
        with:
          endpoint: builder_context

      - name: Login to NGC container registry
        uses: docker/login-action@v3
        with:
          registry: nvcr.io
          username: '$oauthtoken'
          password: ${{ secrets.NGC_NVCF_CREDENTIALS }}

      - name: Build NVCF image
        id: docker_build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/release/cudaq.nvcf.Dockerfile
          build-args: |
            base_image=nvcr.io/nvidia/nightly/cuda-quantum:latest-base
          tags: nvcr.io/${{ secrets.NGC_NVCF_ORG }}/cuda-quantum/cuda-quantum:nightly
          platforms: linux/amd64
          push: true
  
  deploy_nvcf_test_function:
    name: Deploy NVCF function
    runs-on: ubuntu-latest
    needs: build_nvcf_image
    environment: backend-validation
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install NGC CLI
        run: |
          sudo apt-get update && sudo apt-get install -y --no-install-recommends wget
          wget -O ngccli_linux.zip --content-disposition \
            https://api.ngc.nvidia.com/v2/resources/nvidia/ngc-apps/ngc_cli/versions/3.38.0/files/ngccli_linux.zip
          if [ -z "$(sha256sum ngccli_linux.zip | grep -o '427c67684d792b673b63882a6d0cbb8777815095c0f2f31559c1570a91187388 ')" ]; then
            echo "::error::NGC CLI was corrupted during download." && exit 1
          fi
          unzip ngccli_linux.zip && chmod u+x ngc-cli/ngc

      - name: Deploy NVCF Function
        env:
          NGC_CLI_API_KEY: ${{ secrets.NGC_NVCF_CREDENTIALS }}
          NGC_CLI_ORG: ${{ secrets.NGC_NVCF_ORG }}
          NGC_CLI_TEAM: cuda-quantum
        run: |
          create_function_result=$(ngc-cli/ngc cloud-function function create \
            --container-image nvcr.io/${{ secrets.NGC_NVCF_ORG }}/cuda-quantum/cuda-quantum:nightly \
            --api-body-format CUSTOM \
            --inference-port 3030 \
            --health-uri / \
            --inference-url /job \
            --name cudaq-nightly-integration-test \
            ${{ secrets.NVCF_FUNCTION_ID }})
          version_id=$(echo "$create_function" | grep 'Version: \S*' |  head -1 | cut -d ':' -f 2)
          echo "Create version Id: $version_id"

  integration_test:
    name: Integration test
    runs-on: ubuntu-latest
    environment: backend-validation
    container:
      # TODO: switch back to `cuda-quantum:latest` once the publishing image is ready
      image: nvcr.io/nvidia/nightly/cuda-quantum:latest-base
      options: --user root

    steps:
      - name: Get commit SHA
        id: commit-sha
        run: |
          echo "sha=$(cat $CUDA_QUANTUM_PATH/build_info.txt | grep -o 'source-sha: \S*' | cut -d ' ' -f 2)" >> $GITHUB_OUTPUT

      - name: Get code
        uses: actions/checkout@v4
        with:
          ref: ${{ steps.commit-sha.outputs.sha }}
          fetch-depth: 1

      - name: Get tests
        id: gettests
        run: |
          if [ -n "${{ inputs.single_test_name }}" ]; then
            if [ -e ${{ inputs.single_test_name }} ]; then
              echo "testlist=${{ inputs.single_test_name }}" >> $GITHUB_OUTPUT
            else
              # User's request test does not exit
              echo "::error::File ${{ inputs.single_test_name}} not found"
              exit 1
            fi
          else
            filelist="targettests/*/*.cpp"
            echo "testlist=$filelist" >> $GITHUB_OUTPUT
          fi

      - name: Setup quantinum account
        if: github.event_name == 'schedule' || inputs.target == 'nightly' || inputs.target == 'quantinuum'
        run: |
          curl -X POST -H "Content Type: application/json" -d '{ "email":"${{ secrets.BACKEND_LOGIN_EMAIL }}","password":"${{ secrets.QUANTINUUM_PASSWORD }}" }' https://qapi.quantinuum.com/v1/login > credentials.json
          id_token=`cat credentials.json | jq -r '."id-token"'`
          refresh_token=`cat credentials.json | jq -r '."refresh-token"'`
          echo "key: $id_token" > ~/.quantinuum_config
          echo "refresh: $refresh_token" >> ~/.quantinuum_config

      - name: QIR syntax check (Quantinuum)
        if: github.event_name == 'schedule' || inputs.target == 'nightly'
        run: |
          echo "### QIR syntax check (Quantinuum)" >> $GITHUB_STEP_SUMMARY
          export CUDAQ_LOG_LEVEL="info"
          set +e # Allow script to keep going through errors
          test_err_sum=0
          for filename in ${{ steps.gettests.outputs.testlist }}; do
            case $filename in
              targettests/quantinuum/*)
                [ -e "$filename" ] || echo "::error::Couldn't find files ($filename)"
                nvq++ -v $filename -DSYNTAX_CHECK --target quantinuum --quantinuum-machine H1-1SC
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  ./a.out
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                  else
                    echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                else
                  echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
              ;;
            esac
          done
          set -e # Re-enable exit code error checking
          if [ ! $test_err_sum -eq 0 ]; then
            echo "::error::${test_err_sum} tests failed. See step summary for a list of failures"
            exit 1
          fi
        shell: bash

      - name: Submit to IonQ Simulator
        if: (success() || failure()) && (inputs.target == 'ionq' || github.event_name == 'schedule' || inputs.target == 'nightly')
        run: |
          echo "### Submit to IonQ Simulator" >> $GITHUB_STEP_SUMMARY
          export IONQ_API_KEY="${{ secrets.IONQ_API_KEY }}"
          # TODO: remove this flag once https://github.com/NVIDIA/cuda-quantum/issues/512 is addressed.
          export CUDAQ_LOG_LEVEL="info"
          set +e # Allow script to keep going through errors
          test_err_sum=0
          for filename in ${{ steps.gettests.outputs.testlist }}; do
            case $filename in
              targettests/ionq/*)
                [ -e "$filename" ] || echo "::error::Couldn't find files ($filename)"
                nvq++ -v $filename --target ionq
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  ./a.out
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                  else
                    echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                else
                  echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
              ;;
            esac
          done
          set -e # Re-enable exit code error checking
          if [ ! $test_err_sum -eq 0 ]; then
            echo "::error::${test_err_sum} tests failed. See step summary for a list of failures"
            exit 1
          fi
        shell: bash

      - name: Submit to IQM Demo server
        if: (success() || failure()) && (inputs.target == 'iqm' || github.event_name == 'schedule' || inputs.target == 'nightly')
        run: |
          # Must install iqm-cortex-cli to authenticate
          pip install iqm-cortex-cli
          echo "### Submit to IQM Demo server" >> $GITHUB_STEP_SUMMARY
          # IQM demo server info is from: https://demo.qc.iqm.fi/cocos/info/
          cortex init --config-file ${HOME}/.config/iqm-cortex-cli/config.json --tokens-file ${HOME}/.cache/iqm-cortex-cli/tokens.json --auth-server-url https://demo.qc.iqm.fi/auth --client-id iqm_client --realm cortex --username '${{ secrets.IQM_USER }}'
          cortex auth login --username '${{ secrets.IQM_USER }}' --password '${{ secrets.IQM_PASSWORD }}'
          echo ":white_check_mark: Successfully installed iqm-cortex-cli and logged in" >> $GITHUB_STEP_SUMMARY
          # Use the demo machine, which is Adonis architecture
          export IQM_SERVER_URL="https://demo.qc.iqm.fi/cocos"
          export CUDAQ_LOG_LEVEL="info"
          set +e # Allow script to keep going through errors
          test_err_sum=0
          for filename in ${{ steps.gettests.outputs.testlist }}; do
            [ -e "$filename" ] || echo "::error::Couldn't find files ($filename)"
            # Only the following tests are currently supported on IQM
            case $filename in
              targettests/iqm/*)
                nvq++ -DSYNTAX_CHECK --target iqm --iqm-machine Adonis $filename
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  ./a.out
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                  else
                    echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                else
                  echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
              ;;
            esac
          done
          set -e # Re-enable exit code error checking
          cortex auth logout -f
          echo ":white_check_mark: Successfully logged out of IQM" >> $GITHUB_STEP_SUMMARY
          if [ ! $test_err_sum -eq 0 ]; then
            echo "::error::${test_err_sum} tests failed. See step summary for a list of failures"
            exit 1
          fi
        shell: bash

      - name: Submit to OQC Sandbox server
        if: (success() || failure()) && (inputs.target == 'oqc' || github.event_name == 'schedule' || inputs.target == 'nightly')
        run: |
          echo "### Submit to OQC sandbox server" >> $GITHUB_STEP_SUMMARY
          export CUDAQ_LOG_LEVEL="info"
          export OQC_EMAIL="${{ secrets.BACKEND_LOGIN_EMAIL }}"
          export OQC_PASSWORD="${{ secrets.OQC_PASSWORD }}"
          set +e # Allow script to keep going through errors
          test_err_sum=0
          for filename in ${{ steps.gettests.outputs.testlist }}; do
            [ -e "$filename" ] || echo "::error::Couldn't find files ($filename)"
            # Only the following tests are currently supported on OQC
            case $filename in
              targettests/oqc/*)
                nvq++ -DSYNTAX_CHECK --target oqc $filename
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  ./a.out
                  test_status=$?
                  if [ $test_status -eq 0 ]; then
                    echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                  else
                    echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                    test_err_sum=$((test_err_sum+1))
                  fi
                else
                  echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
              ;;
            esac
          done
          set -e # Re-enable exit code error checking
          if [ ! $test_err_sum -eq 0 ]; then
            echo "::error::${test_err_sum} tests failed. See step summary for a list of failures"
            exit 1
          fi
        shell: bash

      - name: Submit to ${{ inputs.target }}
        # The full set of tests used by this step is currently only supported on
        # Quantinuum.  The other supported tests are tested by the step above.
        # The main point of this special step is to run with a special
        # target_machine. It also doesn't use -DSYNTAX_CHECK, so you probably
        # don't want to run this on a simple Syntax Check machine.
        if: inputs.target == 'quantinuum' && github.event_name == 'workflow_dispatch'
        run: |
          if ${{inputs.target == 'ionq'}}; then
            export IONQ_API_KEY="${{ secrets.IONQ_API_KEY }}"
          fi
          for filename in ${{ steps.gettests.outputs.testlist }}; do
            [ -e "$filename" ] || echo "::error::Couldn't find files ($filename)"
            case $filename in
              targettests/quantinuum/*)
                nvq++ -v $filename --target ${{ inputs.target }} --${{ inputs.target }}-machine ${{ inputs.target_machine }}
                CUDAQ_LOG_LEVEL=info ./a.out
              ;;
            esac
          done
        shell: bash
      
      - name: Setup NVCF test function
        if: github.event_name == 'schedule' || inputs.target == 'nightly' || inputs.target == 'nvcf'
        run: |
          # Deploy a test function version with the image for testing

      - name: Submit to NVCF 
        if: (success() || failure()) && (inputs.target == 'nvcf' || github.event_name == 'schedule' || inputs.target == 'nightly')
        run: |
          echo "### Submit to NVCF" >> $GITHUB_STEP_SUMMARY
          export NVCF_API_KEY="${{ secrets.NVCF_API_KEY }}"
          export NVCF_FUNCTION_ID="${{ secrets.NVCF_FUNCTION_ID }}"
          export CUDAQ_LOG_LEVEL="info"
          set +e # Allow script to keep going through errors
          test_err_sum=0
          # FIXME: remove this step
          wget https://curl.haxx.se/ca/cacert.pem 
          # Test all NVQPP execution tests
          for filename in `find test/NVQPP/ -name '*.cpp'`; do
            echo "$filename"
            # Only run tests that require execution (not a syntax-only check)
            if grep -q "ifndef SYNTAX_CHECK" "$filename"; then 
              # TODO: remove --enable-mlir
              nvq++ -v $filename --target nvcf --enable-mlir
              test_status=$?
              if [ $test_status -eq 0 ]; then
                ./a.out
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                else
                  echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
              else
                echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                test_err_sum=$((test_err_sum+1))
              fi
            fi
          done

          # Test all remote-sim tests 
          for filename in `find test/Remote-Sim -name '*.cpp'`; do
            # unsupport_args is a compile error test
            if [[ "$filename" != *"unsupport_args"* ]]; then
              echo "$filename"
              # TODO: remove --enable-mlir
              nvcf_config="--enable-mlir"
              # Look for a --remote-mqpu-auto-launch to determine the number of QPUs
              num_qpus=`cat $filename | grep -oP -m 1 '^//\s*RUN:\s*nvq++.+--remote-mqpu-auto-launch\s+\K\S+'`
              if [ -n "$num_qpus" ]; then
                echo "Intended to run on '$num_qpus' QPUs."
                nvcf_config="$nvcf_config --nvcf-nqpus $num_qpus"
              fi
              nvq++ -v $filename --target nvcf $nvcf_config
              test_status=$?
              if [ $test_status -eq 0 ]; then
                ./a.out
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                else
                  echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
              else
                  echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
              fi
            fi
          done

          # Test C++ examples with NVCF
          for filename in `find examples/cpp/ -name '*.cpp'`; do
            if [[ "$filename" == *"nvcf"* ]]; then
              echo "$filename"
              # TODO: remove --enable-mlir
              nvcf_config="--enable-mlir"
              # Look for a --nvcf-backend flag to nvq++ in the 
              nvcf_backend=`sed -e '/^$/,$d' $filename | grep -oP -m 1 '^//\s*nvq++.+--nvcf-backend\s+\K\S+'`
              if [ -n "$nvcf_backend" ]; then
                echo "Intended for execution on '$nvcf_backend' backend."
                nvcf_config="$nvcf_config --nvcf-backend $nvcf_backend"
              fi
              # Look for a --nvcf-nqpus flag to nvq++ in the 
              num_qpus=`sed -e '/^$/,$d' $filename | grep -oP -m 1 '^//\s*nvq++.+--nvcf-nqpus\s+\K\S+'`
              if [ -n "$num_qpus" ]; then
                echo "Intended to run on '$num_qpus' QPUs."
                nvcf_config="$nvcf_config --nvcf-nqpus $num_qpus"
              fi
              nvq++ -v $filename --target nvcf $nvcf_config
              test_status=$?
              if [ $test_status -eq 0 ]; then
                ./a.out
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  echo ":white_check_mark: Successfully ran test: $filename" >> $GITHUB_STEP_SUMMARY
                else
                  echo ":x: Test failed (failed to execute): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
              else
                  echo ":x: Test failed (failed to compile): $filename" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
              fi
            fi
          done
          
          # Test NVCF Python examples
          for ex in `find examples/python -name '*.py'`; do 
            filename=$(basename -- "$ex")
            filename="${filename%.*}"
            echo "Testing $filename:"
            if [[ "$ex" == *"nvcf"* ]]; then
              # This is an NVCF example
              python3 $ex 1> /dev/null
              test_status=$?
              if [ $test_status -eq 0 ]; then
                echo ":white_check_mark: Successfully ran test: $ex" >> $GITHUB_STEP_SUMMARY
              else
                echo ":x: Test failed (failed to execute): $ex" >> $GITHUB_STEP_SUMMARY
                test_err_sum=$((test_err_sum+1))
              fi
            else
              # Only run examples that are not target-specific (e.g., ionq, iqm)
              if ! grep -q "set_target" "$ex"; then 
                # Use --target command line option to run these examples with
                python3 $ex --target nvcf 1> /dev/null
                test_status=$?
                if [ $test_status -eq 0 ]; then
                  echo ":white_check_mark: Successfully ran test: $ex" >> $GITHUB_STEP_SUMMARY
                else
                  echo ":x: Test failed (failed to execute): $ex" >> $GITHUB_STEP_SUMMARY
                  test_err_sum=$((test_err_sum+1))
                fi
              fi
            fi
          done
          
          set -e # Re-enable exit code error checking
          if [ ! $test_err_sum -eq 0 ]; then
            echo "::error::${test_err_sum} tests failed. See step summary for a list of failures"
            exit 1
          fi
        shell: bash
